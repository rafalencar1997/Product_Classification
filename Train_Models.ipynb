{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from dataset import Dataset\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690 lines skipped (not labeled)\n",
      "0 lines skipped (not text)\n"
     ]
    }
   ],
   "source": [
    "filename = 'datasets/amazon_co-ecommerce_sample.csv'\n",
    "\n",
    "dataset = Dataset(filename)\n",
    "dataset.load(text_field='name', label_field='category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens: 13038\n"
     ]
    }
   ],
   "source": [
    "tokenizer = dataset.tokenize()\n",
    "label_encoder = dataset.label_encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(dataset.data, test_size=0.2)\n",
    "    \n",
    "token_train = tokenizer.texts_to_sequences(data_train.text)\n",
    "text_train = pad_sequences(token_train, maxlen=dataset.max_text())\n",
    "label_train = label_encoder.transform(data_train.label)\n",
    "        \n",
    "token_test = tokenizer.texts_to_sequences(data_test.text)\n",
    "text_test = pad_sequences(token_test, maxlen=dataset.max_text())\n",
    "label_test = label_encoder.transform(data_test.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_MODELS = 'not_trained_models/'\n",
    "\n",
    "MODEL = 'sepcnn__product_description_word2vec_s100'\n",
    "\n",
    "FILE_MODEL         = PATH_MODELS + DATASET + '_model_'+  MODEL  + '.json'\n",
    "FILE_MODEL_WEIGHTS = PATH_MODELS + DATASET + '_model_'+  MODEL  + '.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(FILE_MODEL, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(FILE_MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=\"logs/\" + model.name + '(' + time.asctime() + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_acc', mode='auto',\n",
    "                              min_delta=0.01, patience=5,\n",
    "                              restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=RMSprop(lr=0.005, decay=0.0001), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(pad_train, y_encode_train, \n",
    "                 batch_size=128, epochs=60, initial_epoch=20,\n",
    "                 verbose=1, callbacks=[tensorboard],\n",
    "                 validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_test  = model.evaluate(pad_test, y_encode_test, verbose=0)\n",
    "y_pred = np.argmax(model.predict(pad_test),axis=1)\n",
    "y_pred = le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_tr   = hist.history['acc'][-1]\n",
    "loss_tr  = hist.history['loss'][-1]\n",
    "acc_val  = hist.history['val_acc'][-1]\n",
    "loss_val = hist.history['val_loss'][-1]\n",
    "acc_te   = ev_test[1]\n",
    "loss_te  = ev_test[0]\n",
    "\n",
    "print('Train)      Acc: %.2f%, Loss: %.3f' % 100*acc_tr,  loss_tr)\n",
    "print('Validation) Acc: %.2f%, Loss: %.3f' % 100*acc_val, loss_val)\n",
    "print('Test)       Acc: %.2f%, Loss: %.3f' % 100*acc_te,  loss_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision** is the percentage of samples correctly predicted to that category<br>\n",
    "P = tp / (tp + fp), tp = true positive, fp = false positive <br><br>\n",
    "\n",
    "**Recall** is the percentage of samples of that category predicted correctly<br>\n",
    "R    = tp / (tp + fn), tp = true positive, fn = false Negative <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report = metrics.classification_report(y_real, y_pred)\n",
    "split = class_report.split('\\n')\n",
    "for i, line in enumerate(split):\n",
    "    s = line.split()\n",
    "    if len(s) > 0:\n",
    "        support   = s[-1]\n",
    "        s.pop()\n",
    "        f1_score  = s[-1]\n",
    "        s.pop()\n",
    "        recall    = s[-1]\n",
    "        s.pop()\n",
    "        precision = s[-1]\n",
    "        s.pop()\n",
    "        if len(s) <= 0:\n",
    "            label = 'label'\n",
    "        else:\n",
    "            label = ' '.join(s)\n",
    "        split[i] = [label, precision, recall, f1_score, support]\n",
    "    else:\n",
    "        split[i] = ['']\n",
    "\n",
    "df = pd.DataFrame(split)\n",
    "df.columns = df.loc[0]\n",
    "df = df.drop([0])\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report')\n",
    "df[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "model.save(Path(trained_models_dir, model.name + '.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
